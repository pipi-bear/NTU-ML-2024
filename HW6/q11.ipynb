{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'mnist.scale'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_linear_format(file_path):\n",
    "    X, y = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            y.append(int(parts[0]))  \n",
    "            features = {}\n",
    "            for item in parts[1:]:\n",
    "                index, value = item.split(\":\")\n",
    "                features[int(index)] = float(value)\n",
    "            X.append(features)\n",
    "    return X, np.array(y)\n",
    "\n",
    "X_train, y_train = read_linear_format(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_3 = np.array(y_train == 3)\n",
    "mask_7 = np.array(y_train == 7)\n",
    "\n",
    "indices_3 = np.where(mask_3)[0]\n",
    "indices_7 = np.where(mask_7)[0]\n",
    "\n",
    "X_train_3 = [X_train[i] for i in indices_3]\n",
    "X_train_7 = [X_train[i] for i in indices_7]\n",
    "y_train_3 = y_train[mask_3]\n",
    "y_train_7 = y_train[mask_7]\n",
    "\n",
    "n_features = max(max(feat.keys()) for feat in X_train_3 + X_train_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_array(X_dict, n_features):\n",
    "    X_dense = np.zeros((len(X_dict), n_features))\n",
    "    for i, sample in enumerate(X_dict):\n",
    "        for feat_idx, value in sample.items():\n",
    "            X_dense[i, feat_idx-1] = value  \n",
    "    return X_dense\n",
    "\n",
    "X_train_3_dense = dict_to_array(X_train_3, n_features)\n",
    "X_train_7_dense = dict_to_array(X_train_7, n_features)\n",
    "\n",
    "X_combined = np.vstack([X_train_3_dense, X_train_7_dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit([3, 7])  \n",
    "\n",
    "y_combined = np.concatenate([y_train_3, y_train_7])\n",
    "# the mapping is: 3 -> -1, 7 -> 1\n",
    "y_train_encoded = np.where(y_combined == 3, -1, 1)  \n",
    "\n",
    "y_train_3_encoded = np.full(len(y_train_3), -1)  # All 3s become -1\n",
    "y_train_7_encoded = np.full(len(y_train_7), 1)   # All 7s become 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- note: In `svc()`, rbf kernel is the default setting so need not specify.\n",
    "\n",
    "```python\n",
    "dual_coef_ : array, shape = [n_class-1, n_SV]\n",
    "```\n",
    "$\\rightarrow$ Coefficients (weights) to each support vector in the decision function.\n",
    "\n",
    "In our case, we're doing binary classification so `n_class-1 = 1`.\n",
    "> Therefore we use the index 0 of `dual_coef_`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of result of `dual_coef_`\n",
    "\n",
    "The shape (8730,) means that there are 8730 support vectors.\n",
    "\n",
    "And each coefficient tells that if:\n",
    "- negative $\\Rightarrow$ Support vector belongs to class 1 (the original label is 7)\n",
    "- positive $\\Rightarrow$ Support vector belongs to class -1 (the original label is 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(C = 0.1, gamma = 0.1)\n",
    "svm_classifier.fit(X_combined, y_train_encoded)\n",
    "dual_coefficients = svm_classifier.dual_coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8730,)\n",
      "[-0.04148516 -0.1        -0.1        -0.1        -0.1       ]\n"
     ]
    }
   ],
   "source": [
    "print(dual_coefficients.shape)\n",
    "print(dual_coefficients[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight vector is defined as:\n",
    "> see Lecture 4 slide 10\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\sum_{n=1}^{N} \\alpha_n y_n \\mathbf{z}_n\n",
    "$$\n",
    "\n",
    "And \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "||\\mathbf{w}||^2 \n",
    "&= \\mathbf{w}^T \\mathbf{w} \\\\\n",
    "&= \\sum_{n=1}^{N}\\sum_{m=1}^N \\alpha_n \\alpha_m y_n y_m K(\\mathbf{x}_n, \\mathbf{x}_m) \\\\\n",
    "&= \\sum_{n=1}^{N}\\sum_{m=1}^N \\alpha_n \\alpha_m y_n y_m \\exp(-\\gamma ||\\mathbf{x}_n - \\mathbf{x}_m||^2)\n",
    "\\end{split}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this list to store the result of form (C, gamma, margin)\n",
    "result = []\n",
    "\n",
    "for C in [0.1, 1, 10]:\n",
    "    for gamma in [0.1, 1, 10]:\n",
    "        svm_classifier = SVC(C = C, gamma = gamma)\n",
    "        svm_classifier.fit(X_combined, y_train_encoded)  \n",
    "\n",
    "        support_vectors = svm_classifier.support_vectors_\n",
    "        dual_coefficients = svm_classifier.dual_coef_[0]\n",
    "        support_labels = y_train_encoded[svm_classifier.support_]\n",
    "\n",
    "        w_norm_squared = 0\n",
    "        num_support_vectors = len(support_vectors)\n",
    "\n",
    "        for i in range(num_support_vectors):\n",
    "            for j in range(num_support_vectors):\n",
    "                w_norm_squared += (\n",
    "                    dual_coefficients[i] * dual_coefficients[j]\n",
    "                    * support_labels[i] * support_labels[j]\n",
    "                    * np.exp(-gamma * np.linalg.norm(support_vectors[i] - support_vectors[j])**2)\n",
    "                )\n",
    "        \n",
    "        margin = 1.0 / np.sqrt(w_norm_squared)\n",
    "        result.append((C, gamma, margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results Table\n",
      "--------------------------------------------------\n",
      "Margin for each combination:\n",
      "      gamma=0.1  gamma=1.0  gamma=10.0\n",
      "C                                     \n",
      "0.1    0.041274   0.090780    0.090793\n",
      "1.0    0.018166   0.009078    0.009079\n",
      "10.0   0.017794   0.008984    0.008982\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame(result, columns=['C', 'gamma', 'margin'])\n",
    "df_pivot = df_results.pivot(index='C', columns='gamma', values='margin')\n",
    "df_pivot.columns = [f'gamma={gamma}' for gamma in df_pivot.columns]\n",
    "\n",
    "print(\"\\nResults Table\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Margin for each combination:\")\n",
    "print(df_pivot.to_string(float_format=lambda margin: '{:,.6f}'.format(margin)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
