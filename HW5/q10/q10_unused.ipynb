{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct problem in scipy format\n",
    "\n",
    "> README.md line 150-154\n",
    "\n",
    "For sparse data: scipy csr_matrix((data, (row_ind, col_ind))\n",
    "\n",
    "y, x = np.asarray([1,-1]), scipy.sparse.csr_matrix(([1, 1, -1, -1], ([0, 0, 1, 1], [0, 2, 0, 2])))\n",
    "\n",
    "prob  = problem(y, x)\n",
    "\n",
    "param = parameter('-s 0 -c 4 -B 1')\n",
    "\n",
    "m = train(prob, param)\n",
    "\n",
    "$\\rightarrow$ the `csr_matrix` represents \"Compressed Sparse Row matrix\", and only stores nonzero values. This data structure consists of three components, which are:\n",
    "\n",
    "1. data\n",
    "2. row_ind\n",
    "3. col_ind\n",
    "\n",
    "Like in the example above, the `data` is `[1, 1, -1, -1]`, and the `row_ind` is `[0, 0, 1, 1]`, and the `col_ind` is `[0, 2, 0, 2]`.\n",
    "\n",
    "$\\rightarrow$ the `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform X\n",
    "\n",
    "We transform the original data list `X` (which is a list of dictionaries) into a scipy csr_matrix.\n",
    "\n",
    "This requires us to iterate through each element in `X`, and since each example is a row in the matrix, we:\n",
    "\n",
    "1. append the value into `data`\n",
    "2. append the index of this example into `row_ind`\n",
    "3. append the key into `col_ind`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y):\n",
    "    return np.asarray([1 if y_i == 2 else -1 for y_i in y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to call `train()`\n",
    "\n",
    "There are three ways to call train()\n",
    "\n",
    "1. model = train(y, x [, 'training_options'])\n",
    "2. model = train(prob [, 'training_options'])\n",
    "3. model = train(prob, param)\n",
    "\n",
    "We use the third way to call `train()`, which in detail is:\n",
    "- `prob`: a problem instance generated by calling problem(y, x).\n",
    "- `param`: a parameter instance generated by calling parameter('training_options')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate nodearray\n",
    "\n",
    "Use the function: `gen_feature_nodearray(xi [,feature_max=None])`\n",
    "\n",
    "Generate a feature vector from a Python list/tuple/dictionary, numpy ndarray or tuple of (index, data):\n",
    "\n",
    "For example: xi_ctype, max_idx = gen_feature_nodearray({1:1, 3:1, 5:-2})\n",
    "- `xi_ctype`: the returned feature_nodearray (a ctypes structure)\n",
    "- `max_idx`: the maximal feature index of xi\n",
    "- `feature_max`: if feature_max is assigned, features with indices larger than\n",
    "             feature_max are removed.\n",
    "\n",
    "Usage example:\n",
    "\n",
    "```python\n",
    "m = liblinear.train(prob, param) # m is a ctype pointer to a model\n",
    "x0, max_idx = gen_feature_nodearray({1:1, 3:1})\n",
    "label = liblinear.predict(m, x0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_ctype = []\n",
    "for x_i in X_train:\n",
    "    x_i_ctype, _ = gen_feature_nodearray(x_i)\n",
    "    Xtrain_ctype.append(x_i_ctype)\n",
    "\n",
    "Xtest_ctype = []\n",
    "for x_i in X_test:\n",
    "    x_i_ctype, _ = gen_feature_nodearray(x_i)\n",
    "    Xtest_ctype.append(x_i_ctype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in tqdm(range(5)):\n",
    "    min_Ein = np.inf\n",
    "    opt_log10_lambda = 0\n",
    "    seed = np.random.seed(experiment)\n",
    "    for log10_lambda in (-2, -1, 0, 1, 2, 3):\n",
    "        train_pred_res = []\n",
    "        c = 1 / (10 ** log10_lambda)\n",
    "        prob = problem(y_train, X_train)\n",
    "        param = parameter('-s 6 -c ' + str(c))\n",
    "        model = train(prob, param)\n",
    "\n",
    "        for x_i_ctype in Xtrain_ctype:\n",
    "            train_pred_res.append(liblinear.predict(model, x_i_ctype))\n",
    "        Ein = ZeroOneError(train_pred_res, y_train)\n",
    "\n",
    "        if Ein == min_Ein:\n",
    "            opt_log10_lambda = max(opt_log10_lambda, log10_lambda)      # break tie by choosing the larger lambda\n",
    "        elif Ein < min_Ein:\n",
    "            minEin = Ein\n",
    "            opt_log10_lambda = log10_lambda\n",
    "\n",
    "    #print('The best log_10(Î»*) = ', opt_log10_lambda)\n",
    "    c_test  = 1 / (10 ** opt_log10_lambda)\n",
    "    prob_test = problem(y_test, X_test)\n",
    "    param_test = parameter('-s 6 -c ' + str(c_test))\n",
    "    model_test = train(prob_test, param_test)\n",
    "\n",
    "    test_pred_res = []\n",
    "    for x_i_ctype in Xtest_ctype:\n",
    "        test_pred_res.append(liblinear.predict(model_test, x_i_ctype))\n",
    "    Eout = ZeroOneError(test_pred_res, y_test)\n",
    "    print(f'Eout for experiment {experiment} is {Eout}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
